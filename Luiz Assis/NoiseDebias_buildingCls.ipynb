{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,progressbar\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import pandas as pd\n",
    "import astropy.io.fits as fits\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sys.path.insert(1, '/home/luiz/IC/Codes/Noise_Debias/scripts')\n",
    "import gmca4im_lib2 as g4i\n",
    "import Extension4BINGO as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "################   GENERAL INFORMATIONS   #############\n",
    "#######################################################\n",
    "method           = \"ICA\"\n",
    "wtransform       = \"starlet\"\n",
    "maps_wout_mean   = True\n",
    "apply_mask       = False\n",
    "add_noise        = False\n",
    "#######################################################\n",
    "################   WAVELETS PARAMETERS   ##############\n",
    "#######################################################\n",
    "#####\n",
    "# The main aim is to have:\n",
    "# Starlet, Axisymmetric, spin-Directional, Wavelets Standard from PyWavelets, Curvelets, Counturlets, Shearlets, Ridgelets and so on\n",
    "#####\n",
    "J     = 3  #number of scales\n",
    "use_c = True  # if you will use wavelet scale in the analysis\n",
    "##############\n",
    "# S2LET code\n",
    "# If you to use wtransforms by S2Let code, please, fill in the variables below:\n",
    "L        = None #If you write \"None\", it will use L=3*nside\n",
    "J_min    = 1\n",
    "B        = 5     \n",
    "N        = 3  # Number of directions (This is for Directional only)\n",
    "spin     = 0  # set to 0 for temperature. if non-zero, plotting routines must be changed! (This is for Directional only)\n",
    "upsample = 0  # 1 means all scales at full resolution L # 0 means multiresolution wavelet transform (This is for Directional only)\n",
    "# In the S2LET code, J scales is defined by code and not by J above.\n",
    "\n",
    "##############\n",
    "# PyWavelets\n",
    "Jpwt = 2 #number of scales\n",
    "pywttype = \"db1\" \n",
    "##############\n",
    "# Curvelets\n",
    "\n",
    "##############\n",
    "# Counturlets\n",
    "\n",
    "##############\n",
    "# Shearlets\n",
    "\n",
    "##############\n",
    "# Ridgelets\n",
    "\n",
    "#######################################################\n",
    "#### COMPONENT SEPARATION #############################\n",
    "#######################################################\n",
    "n_s = 4  #number of sources to be estimated\n",
    "######## FastICA PARAMETERS \n",
    "whiten = True  ######## Maintain True\n",
    "fun = 'logcosh' #exp,logcosh or\n",
    "max_iter = 100 \n",
    "tol = 0.0001\n",
    "######## GMCA PARAMETERS   \n",
    "mints = 0.05 # min threshold (what is sparse compared to noise?)\n",
    "nmax  = 100 # number of iterations (usually 100 is safe)\n",
    "L0    = 0   # switch between L0 norm (1) or L1 norm (0)\n",
    "#######################################################\n",
    "AInit     = None\n",
    "ColFixed  = None\n",
    "whitening = False\n",
    "epsi      = 1e-3\n",
    "verbose   = False\n",
    "#GMCAExtension\n",
    "div          = 1 #  J+1  #J/div will should be even number\n",
    "without_covx = True # if your mixmatrix estimated will use covariance matrix of the observer data with ponderation\n",
    "#######################################################\n",
    "################   DEBIAS PARAMETERS   ################\n",
    "#######################################################\n",
    "seed_used = 10                                            \n",
    "#######################################################\n",
    "################   PATHS PARAMETERS   #################\n",
    "#######################################################\n",
    "#path outputs\n",
    "pathout       = \"/home/luiz/IC/Datas_Maps/Cls/mapateste123321123321123\" #Put here your path to the output cls\n",
    "cl_type_save  = \"reconstruction\" #You should choice between reconstruction or residuals cls values\n",
    "#######################################################\n",
    "################   NAME FILES PARAMETERS   ############\n",
    "#######################################################\n",
    "# Name of FITS files inside of the pathmaps\n",
    "name_mask = \"Mask_tot256.fits\" #put this file in the same directory of the other maps\n",
    "\n",
    "#Directory names\n",
    "dir_observed  = \"/home/luiz/IC/Datas_Maps/Cubos_Input_L10_L25_White_Noise\"\n",
    "dir_mask      = \"/home/luiz/IC/Datas_Maps/Mask\"\n",
    "dir_prior     = \"/home/luiz/IC/Datas_Maps/Cubos_Prior_WN\" \n",
    "dir_noise     = \"/home/luiz/IC/Datas_Maps/wn_masked\"         #Put here directory name of the noise maps \n",
    "dir_pure      = \"/home/luiz/IC/Datas_Maps/Cubos_21cm_Masked\" #Put here directory name of the pure maps \n",
    "dir_projprior = \"/home/luiz/IC/Datas_Maps/Cubos_Prior_WN\"    #Put here directory name of the prior maps\n",
    "dir_projnoise = \"/home/luiz/IC/Datas_Maps/wn_masked\"         #Put here directory name of the noise maps\n",
    "dir_projpure  = \"/home/luiz/IC/Datas_Maps/Cubos_21cm_Masked\" #Put here directory name of the pure maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_maps = pd.Series({\"without_mean\":maps_wout_mean, \"apply_mask\":apply_mask, \"add_noise\":add_noise, \"cl_type_save\":cl_type_save})\n",
    "params_CS   = pd.Series({\"method\":method,\n",
    "                         \"A_ini\":AInit, \"ColFixed\":ColFixed, \"whitening\":whitening, \"epsi\":epsi, \"verbose\":verbose, \"ns\":n_s, \"mints\":mints,\"nmax\":nmax, \"L0\":L0, \"division\":div, \"without_covx\":without_covx, \"seed_used\":seed_used,\n",
    "                         \"whiten\":whiten, \"fun\":fun, \"max_iter\":max_iter, \"tol\":tol})\n",
    "params_WT   = pd.Series({\"wtransform\":np.asarray(wtransform), \"use_c\":use_c, \"J\":J, \n",
    "                         \"L\":L, \"Jmin\":J_min, \"B\": B, \"N\":N, \"spin\":spin, \"upsample\":upsample,\n",
    "                         \"Jpwt\":Jpwt, \"pywttype\":pywttype.lower()})\n",
    "params_path = pd.Series({\"pathout\":pathout, \"dir_observed\":dir_observed, \"dir_mask\":dir_mask, \"dir_noise\":dir_noise, \"dir_prior\":dir_prior,\"dir_pure\":dir_pure, \"name_mask\":name_mask})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Foregrounds + HI + Noise\n",
    "$C_{\\ell}^{\\textrm{FG+HI+N}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16 of 16) |########################| Elapsed Time: 3:25:57 Time:  3:25:57\n"
     ]
    }
   ],
   "source": [
    "names = np.asarray(os.listdir(params_path.dir_observed))\n",
    "nseed = cs.extracting_seed_from_filenames(vectornames=names)\n",
    "\n",
    "\n",
    "timei = time.time()\n",
    "params_maps[\"getdata\"] = \"observed\"\n",
    "subdirs = cs.checkdir(params_path.pathout, subdirs=[\"21cm\",\"foregrounds\",\"mixmatrix\"])\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)\n",
    "    time0 = time.time()\n",
    "    params_path[\"name_observed\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    X = cs.maps2CSmaps(X, params_WT, params_CS)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)\n",
    "    del X\n",
    "    time0   = time.time()-time0\n",
    "    #print(\"[L{0}] Loop time: {1:.2f} min\".format(nseed[i],time0/60))\n",
    "clear_output(wait=True)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise\n",
    "$C_{\\ell}^{\\textrm{N}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16 of 16) |########################| Elapsed Time: 0:05:11 Time:  0:05:11\n"
     ]
    }
   ],
   "source": [
    "names = np.asarray(os.listdir(params_path.dir_noise))\n",
    "nseed = cs.extracting_seed_from_filenames(vectornames=names)\n",
    "\n",
    "timei   = time.time()\n",
    "params_maps[\"getdata\"] = \"noise\"\n",
    "subdirs = [\"noise\"]\n",
    "\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)\n",
    "    time0 = time.time()\n",
    "    params_path[\"name_noise\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior\n",
    "$C_{\\ell}^{\\textrm{prior}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16 of 16) |########################| Elapsed Time: 0:10:51 Time:  0:10:51\n"
     ]
    }
   ],
   "source": [
    "names = np.asarray(os.listdir(params_path.dir_prior))\n",
    "nseed = cs.extracting_seed_from_filenames(vectornames=names)\n",
    "\n",
    "timei   = time.time()\n",
    "params_maps[\"getdata\"] = \"prior\"\n",
    "subdirs = [\"prior\"]\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=names.size)    \n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)    \n",
    "    time0 = time.time()\n",
    "    params_path[\"name_prior\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21cm pure\n",
    "$C_{\\ell}^{\\textrm{pure}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16 of 16) |########################| Elapsed Time: 0:14:47 Time:  0:14:47\n"
     ]
    }
   ],
   "source": [
    "names = np.asarray(os.listdir(params_path.dir_pure))\n",
    "#nseed = np.asarray([iname.split(\"_\")[-1].split(\".\")[0][:3] for iname in names])#selecting L-number from string name\n",
    "nseed = cs.extracting_seed_from_filenames(vectornames=names)\n",
    "\n",
    "timei   = time.time()\n",
    "params_maps[\"getdata\"] = \"pure\"\n",
    "subdirs = [\"pure\"]\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "    \n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)    \n",
    "    time0 = time.time()\n",
    "    params_path[\"name_pure\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "    \n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21cm proj pure\n",
    "$C_{\\ell}^{\\textrm{proj pure}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16 of 16) |########################| Elapsed Time: 0:15:14 Time:  0:15:14\n"
     ]
    }
   ],
   "source": [
    "names = np.asarray(os.listdir(params_path.dir_pure))\n",
    "nseed = cs.extracting_seed_from_filenames(vectornames=names)\n",
    "\n",
    "timei   = time.time()\n",
    "params_maps[\"getdata\"] = \"pure\"\n",
    "subdirs = [\"projpure\"]\n",
    "L0      = \"L{}\".format(params_CS.seed_used)\n",
    "A       = cs.loadmixmatrix(params_path.pathout,\"mixmatrix\")\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)    \n",
    "    time0 = time.time()\n",
    "    params_path[\"name_pure\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, A=A[L0], params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21cm  proj noise\n",
    "$C_{\\ell}^{\\textrm{proj noise}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16 of 16) |########################| Elapsed Time: 0:15:39 Time:  0:15:39\n"
     ]
    }
   ],
   "source": [
    "names = np.asarray(os.listdir(params_path.dir_noise))\n",
    "nseed = cs.extracting_seed_from_filenames(vectornames=names)\n",
    "timei   = time.time()\n",
    "params_maps[\"getdata\"] = \"noise\"\n",
    "subdirs = [\"projnoise\"]\n",
    "L0      = \"L{}\".format(params_CS.seed_used)\n",
    "A       = cs.loadmixmatrix(params_path.pathout,\"mixmatrix\")\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "    \n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)    \n",
    "    time0 = time.time()\n",
    "    params_path[\"name_noise\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, A=A[L0], params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21cm  proj prior\n",
    "$C_{\\ell}^{\\textrm{proj prior}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (16 of 16) |########################| Elapsed Time: 0:15:03 Time:  0:15:03\n"
     ]
    }
   ],
   "source": [
    "names   = np.asarray(os.listdir(params_path.dir_prior))\n",
    "#nseed   = np.asarray([iname.split(\"_\")[-1].split(\".\")[0][:3] for iname in names])#selecting L-number from string name\n",
    "nseed = cs.extracting_seed_from_filenames(vectornames=names)\n",
    "\n",
    "timei   = time.time()\n",
    "params_maps[\"getdata\"] = \"prior\"\n",
    "subdirs = [\"projprior\"]\n",
    "L0      = \"L{}\".format(params_CS.seed_used)\n",
    "A       = cs.loadmixmatrix(params_path.pathout,\"mixmatrix\")\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=names.size)\n",
    "for i,iname in enumerate(names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)    \n",
    "    time0 = time.time()\n",
    "    params_path[\"name_prior\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed[i])\n",
    "    cs.saveouts(mrec=X, A=A[L0], params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
