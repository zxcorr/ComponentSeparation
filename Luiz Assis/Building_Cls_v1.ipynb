{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# SYSTEM\n",
    "import os\n",
    "import sys\n",
    "#######################################################\n",
    "# MATH\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import pandas as pd\n",
    "import astropy.io.fits as fits\n",
    "#######################################################\n",
    "# TIMERS\n",
    "import progressbar\n",
    "import time\n",
    "#######################################################\n",
    "# ALESSANDRO/ISABELLA\n",
    "sys.path.insert(1, '/home/luiz/IC/Codes/Noise_Debias/scripts')\n",
    "import gmca4im_lib2 as g4i\n",
    "import Extension4BINGO as cs\n",
    "#######################################################\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# GENERAL\n",
    "n_realization    = 8          # Number of maps to be produced on the analysis, from a total known number of maps\n",
    "method           = \"ICA\"      # Component Separation Method to be used\n",
    "wtransform       = \"identity\" # Wavelet transform to be used\n",
    "maps_wout_mean   = True       # A parameter for centering data with mean = 0\n",
    "\n",
    "apply_mask       = False      # A parameter to ica sklearn function\n",
    "add_noise        = False      # A parameter to ica sklearn function\n",
    "#######################################################\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# WAVELET PARAMETERS\n",
    "\n",
    "# The main aim is to have:\n",
    "\n",
    "# STARLETS\n",
    "J     = 1       # Number of scales\n",
    "use_c = True    # If you will use wavelet scale in the analysis\n",
    "\n",
    "# S2LET\n",
    "# If you to use wtransforms by S2Let code, please, fill in the variables below:\n",
    "L        = None # If you write \"None\", it will use L=3*nside\n",
    "J_min    = 1    #\n",
    "B        = 5    #   \n",
    "N        = 3    # Number of directions (This is for Directional only)\n",
    "spin     = 0    # Set to 0 for temperature. if non-zero, plotting routines must be changed! (This is for Directional only)\n",
    "upsample = 0    # 1 means all scales at full resolution L # 0 means multiresolution wavelet transform (This is for Directional only)\n",
    "# In the S2LET code, J scales is defined by code and not by J above.\n",
    "\n",
    "# PYWAVELETS\n",
    "Jpwt = 2 # Number of scales\n",
    "pywttype = \"db1\" \n",
    "\n",
    "# CURVELETS\n",
    "\n",
    "# COUNTURLETS\n",
    "\n",
    "# SHEARLETS\n",
    "\n",
    "# RIDGELETS\n",
    "#######################################################\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# COMPONENT SEPARATION PARAMETERS\n",
    "\n",
    "# ICA\n",
    "n_s              = 2          #Number of sources to be estimated\n",
    "whiten           = True  ######## Maintain True\n",
    "fun              = 'logcosh' # exp,logcosh or tanh\n",
    "max_iter         = 100 \n",
    "tol              = 0.0001\n",
    "\n",
    "# GMCA\n",
    "mints = 0.05 # min threshold (what is sparse compared to noise?)\n",
    "nmax  = 100 # number of iterations (usually 100 is safe)\n",
    "L0    = 0   # switch between L0 norm (1) or L1 norm (0)\n",
    "\n",
    "AInit     = None\n",
    "ColFixed  = None\n",
    "whitening = False\n",
    "epsi      = 1e-3\n",
    "verbose   = False\n",
    "# GMCAExtension\n",
    "div          = 1 #  J+1  #J/div will should be even number\n",
    "without_covx = True # if your mixmatrix estimated will use covariance matrix of the observer data with ponderation\n",
    "#######################################################\n",
    "\n",
    "\n",
    "#######################################################\n",
    "# DEBIAS PARAMETERS\n",
    "seed_used = 10\n",
    "\n",
    "#######################################################\n",
    "# PATH PARAMETERS\n",
    "pathout       = \"/home/luiz/IC/Datas_Maps/Cls/NOVOCODIGO_TESTE\" #Put here your path to the output cls\n",
    "cl_type_save  = \"reconstruction\" #You should choice between reconstruction or residuals cls values\n",
    "\n",
    "#######################################################\n",
    "# NAME FILES PARAMETERS\n",
    "# Name of FITS files inside of the pathmaps\n",
    "name_mask = \"Mask_tot256.fits\" #put this file in the same directory of the other maps\n",
    "#Directory names\n",
    "dir_observed  = \"/home/luiz/IC/Datas_Maps/Cubos_Input_L10_L25_White_Noise\"\n",
    "dir_mask      = \"/home/luiz/IC/Datas_Maps/Mask\"\n",
    "dir_prior     = \"/home/luiz/IC/Datas_Maps/Cubos_Prior_WN\" \n",
    "dir_noise     = \"/home/luiz/IC/Datas_Maps/wn_masked\"         #Put here directory name of the noise maps \n",
    "dir_pure      = \"/home/luiz/IC/Datas_Maps/Cubos_21cm_Masked\" #Put here directory name of the pure maps \n",
    "dir_projprior = \"/home/luiz/IC/Datas_Maps/Cubos_Prior_WN\"    #Put here directory name of the prior maps\n",
    "dir_projnoise = \"/home/luiz/IC/Datas_Maps/wn_masked\"         #Put here directory name of the noise maps\n",
    "dir_projpure  = \"/home/luiz/IC/Datas_Maps/Cubos_21cm_Masked\" #Put here directory name of the pure maps\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# ?\n",
    "params_maps = pd.Series({\"without_mean\":maps_wout_mean, \"apply_mask\":apply_mask, \"add_noise\":add_noise, \"cl_type_save\":cl_type_save})\n",
    "params_CS   = pd.Series({\"method\":method,\n",
    "                         \"A_ini\":AInit, \"ColFixed\":ColFixed, \"whitening\":whitening, \"epsi\":epsi, \"verbose\":verbose, \"ns\":n_s, \"mints\":mints,\"nmax\":nmax, \"L0\":L0, \"division\":div, \"without_covx\":without_covx, \"seed_used\":seed_used,\n",
    "                         \"whiten\":whiten, \"fun\":fun, \"max_iter\":max_iter, \"tol\":tol})\n",
    "params_WT   = pd.Series({\"wtransform\":np.asarray(wtransform), \"use_c\":use_c, \"J\":J, \n",
    "                         \"L\":L, \"Jmin\":J_min, \"B\": B, \"N\":N, \"spin\":spin, \"upsample\":upsample,\n",
    "                         \"Jpwt\":Jpwt, \"pywttype\":pywttype.lower()})\n",
    "params_path = pd.Series({\"pathout\":pathout, \"dir_observed\":dir_observed, \"dir_mask\":dir_mask, \"dir_noise\":dir_noise, \"dir_prior\":dir_prior,\"dir_pure\":dir_pure, \"name_mask\":name_mask})\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FOREGROUNDS + HI + MIXMATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8 of 8) |##########################| Elapsed Time: 0:01:26 Time:  0:01:26\n"
     ]
    }
   ],
   "source": [
    "map_names = np.asarray(os.listdir(params_path.dir_observed))                  # Goes to directory with observed maps and puts their names on an array of strings\n",
    "map_names = np.random.choice(map_names, size = n_realization, replace=False)  # Randomically choose \"n\" maps from a total \"m\", n<m\n",
    "nseed_0 = cs.extracting_seed_from_filenames(vectornames=map_names)            # Create vector with the number labels of maps. Map1 = seed 1\n",
    "\n",
    "params_maps[\"getdata\"] = \"observed\"  #?\n",
    "subdirs = cs.checkdir(params_path.pathout, subdirs=[\"21cm\",\"foregrounds\",\"mixmatrix\"]) # Create the directories for outputs\n",
    "\n",
    "timei = time.time()\n",
    "bar = progressbar.ProgressBar(maxval=map_names.size)\n",
    "for i,iname in enumerate(map_names):  # Loop that does Component Separation Analysis. number of loops = length of map_names\n",
    "    clear_output(wait=True) #??\n",
    "    bar.update(i)\n",
    "    time0 = time.time() #?\n",
    "    params_path[\"name_observed\"] = iname # aqui começa a análise de component separation e wavelets, \n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    X = cs.maps2CSmaps(X, params_WT, params_CS)         # chegando nesse ponto, temos as matrizes já com os Cls, portanto já temos o espectro de potencia após passar pelo ICA\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed_0[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)\n",
    "    del X\n",
    "    time0   = time.time()-time0 #?\n",
    "clear_output(wait=True)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8 of 8) |##########################| Elapsed Time: 0:00:23 Time:  0:00:23\n"
     ]
    }
   ],
   "source": [
    "map_names = np.asarray(os.listdir(params_path.dir_noise))                  # Same for different directory\n",
    "nseed_1 = cs.extracting_seed_from_filenames(vectornames=map_names)         # Extract new seeds\n",
    "index=[] \n",
    "\n",
    "for i in range(len(nseed_0)):                        # This loop will make sure that we get only the seeds from the first box, nseed_0. (we avoid the situation where we have the map with seed 15 in one directory (observed) but not in another (proj pure))\n",
    "    n0 = nseed_0[i]\n",
    "    index.append(np.where(nseed_1==n0)[0][0])\n",
    "index = np.asarray(index)\n",
    "map_names = map_names[index]\n",
    "nseed_1 = nseed_1[index]\n",
    "\n",
    "params_maps[\"getdata\"] = \"noise\" # Same for different directory\n",
    "subdirs = [\"noise\"]              # Same for different directory\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):     #This will check if there is a directory, delete and replace if it already exists\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "    \n",
    "timei   = time.time()\n",
    "bar = progressbar.ProgressBar(maxval=map_names.size)\n",
    "for i,iname in enumerate(map_names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)\n",
    "    time0 = time.time()\n",
    "    params_path[\"name_noise\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed_1[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8 of 8) |##########################| Elapsed Time: 0:00:22 Time:  0:00:22\n"
     ]
    }
   ],
   "source": [
    "map_names = np.asarray(os.listdir(params_path.dir_prior))                  # Same for different directory\n",
    "nseed_1 = cs.extracting_seed_from_filenames(vectornames=map_names)         # Extract new seeds\n",
    "index=[] \n",
    "\n",
    "for i in range(len(nseed_0)):                        # This loop will make sure that we get only the seeds from the first box, nseed_0. (we avoid the situation where we have the map with seed 15 in one directory (observed) but not in another (proj pure))\n",
    "    n0 = nseed_0[i]\n",
    "    index.append(np.where(nseed_1==n0)[0][0])\n",
    "index = np.asarray(index)\n",
    "map_names = map_names[index]\n",
    "nseed_1 = nseed_1[index]\n",
    "\n",
    "params_maps[\"getdata\"] = \"prior\" # Same for different directory\n",
    "subdirs = [\"prior\"]              # Same for different directory\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):     #This will check if there is a directory, delete and replace if it already exists\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "    \n",
    "timei   = time.time()\n",
    "bar = progressbar.ProgressBar(maxval=map_names.size)\n",
    "for i,iname in enumerate(map_names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)\n",
    "    time0 = time.time()\n",
    "    params_path[\"name_prior\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed_1[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21CM PURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8 of 8) |##########################| Elapsed Time: 0:00:23 Time:  0:00:23\n"
     ]
    }
   ],
   "source": [
    "map_names = np.asarray(os.listdir(params_path.dir_pure))                  # Same for different directory\n",
    "nseed_1 = cs.extracting_seed_from_filenames(vectornames=map_names)         # Extract new seeds\n",
    "index=[] \n",
    "\n",
    "for i in range(len(nseed_0)):                        # This loop will make sure that we get only the seeds from the first box, nseed_0. (we avoid the situation where we have the map with seed 15 in one directory (observed) but not in another (proj pure))\n",
    "    n0 = nseed_0[i]\n",
    "    index.append(np.where(nseed_1==n0)[0][0])\n",
    "index = np.asarray(index)\n",
    "map_names = map_names[index]\n",
    "nseed_1 = nseed_1[index]\n",
    "\n",
    "params_maps[\"getdata\"] = \"pure\" # Same for different directory\n",
    "subdirs = [\"pure\"]              # Same for different directory\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):     #This will check if there is a directory, delete and replace if it already exists\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "    \n",
    "timei   = time.time()\n",
    "bar = progressbar.ProgressBar(maxval=map_names.size)\n",
    "for i,iname in enumerate(map_names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)\n",
    "    time0 = time.time()\n",
    "    params_path[\"name_pure\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed_1[i])\n",
    "    cs.saveouts(mrec=X, params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  21CM PROJ PURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8 of 8) |##########################| Elapsed Time: 0:00:25 Time:  0:00:25\n"
     ]
    }
   ],
   "source": [
    "map_names = np.asarray(os.listdir(params_path.dir_pure))                  # Same for different directory\n",
    "nseed_1 = cs.extracting_seed_from_filenames(vectornames=map_names)         # Extract new seeds\n",
    "index=[] \n",
    "\n",
    "for i in range(len(nseed_0)):                        # This loop will make sure that we get only the seeds from the first box, nseed_0. (we avoid the situation where we have the map with seed 15 in one directory (observed) but not in another (proj pure))\n",
    "    n0 = nseed_0[i]\n",
    "    index.append(np.where(nseed_1==n0)[0][0])\n",
    "index = np.asarray(index)\n",
    "map_names = map_names[index]\n",
    "nseed_1 = nseed_1[index]\n",
    "\n",
    "params_maps[\"getdata\"] = \"pure\" # Same for different directory\n",
    "subdirs = [\"projpure\"]              # Same for different directory\n",
    "\n",
    "L0      = \"L{}\".format(params_CS.seed_used)\n",
    "A       = cs.loadmixmatrix(params_path.pathout,\"mixmatrix\")\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):     #This will check if there is a directory, delete and replace if it already exists\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "    \n",
    "timei   = time.time()\n",
    "bar = progressbar.ProgressBar(maxval=map_names.size)\n",
    "for i,iname in enumerate(map_names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)\n",
    "    time0 = time.time()\n",
    "    params_path[\"name_pure\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed_1[i])\n",
    "    cs.saveouts(mrec=X, A=A[L0], params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21CM PROJ NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8 of 8) |##########################| Elapsed Time: 0:00:25 Time:  0:00:25\n"
     ]
    }
   ],
   "source": [
    "map_names = np.asarray(os.listdir(params_path.dir_noise))                  # Same for different directory\n",
    "nseed_1 = cs.extracting_seed_from_filenames(vectornames=map_names)         # Extract new seeds\n",
    "index=[] \n",
    "\n",
    "for i in range(len(nseed_0)):                        # This loop will make sure that we get only the seeds from the first box, nseed_0. (we avoid the situation where we have the map with seed 15 in one directory (observed) but not in another (proj pure))\n",
    "    n0 = nseed_0[i]\n",
    "    index.append(np.where(nseed_1==n0)[0][0])\n",
    "index = np.asarray(index)\n",
    "map_names = map_names[index]\n",
    "nseed_1 = nseed_1[index]\n",
    "\n",
    "params_maps[\"getdata\"] = \"noise\" # Same for different directory\n",
    "subdirs = [\"projnoise\"]              # Same for different directory\n",
    "\n",
    "L0      = \"L{}\".format(params_CS.seed_used)\n",
    "A       = cs.loadmixmatrix(params_path.pathout,\"mixmatrix\")\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):     #This will check if there is a directory, delete and replace if it already exists\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "    \n",
    "timei   = time.time()\n",
    "bar = progressbar.ProgressBar(maxval=map_names.size)\n",
    "for i,iname in enumerate(map_names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)\n",
    "    time0 = time.time()\n",
    "    params_path[\"name_noise\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed_1[i])\n",
    "    cs.saveouts(mrec=X, A=A[L0], params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21CM PROJ PRIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (8 of 8) |##########################| Elapsed Time: 0:00:29 Time:  0:00:29\n"
     ]
    }
   ],
   "source": [
    "map_names = np.asarray(os.listdir(params_path.dir_prior))                  # Same for different directory\n",
    "nseed_1 = cs.extracting_seed_from_filenames(vectornames=map_names)         # Extract new seeds\n",
    "index=[] \n",
    "\n",
    "for i in range(len(nseed_0)):                        # This loop will make sure that we get only the seeds from the first box, nseed_0. (we avoid the situation where we have the map with seed 15 in one directory (observed) but not in another (proj pure))\n",
    "    n0 = nseed_0[i]\n",
    "    index.append(np.where(nseed_1==n0)[0][0])\n",
    "index = np.asarray(index)\n",
    "map_names = map_names[index]\n",
    "nseed_1 = nseed_1[index]\n",
    "\n",
    "params_maps[\"getdata\"] = \"prior\" # Same for different directory\n",
    "subdirs = [\"projprior\"]              # Same for different directory\n",
    "\n",
    "L0      = \"L{}\".format(params_CS.seed_used)\n",
    "A       = cs.loadmixmatrix(params_path.pathout,\"mixmatrix\")\n",
    "if not os.path.isdir(os.path.join(params_path.pathout,subdirs[0])):     #This will check if there is a directory, delete and replace if it already exists\n",
    "    os.makedirs(os.path.join(params_path.pathout,subdirs[0]))\n",
    "    \n",
    "timei   = time.time()\n",
    "bar = progressbar.ProgressBar(maxval=map_names.size)\n",
    "for i,iname in enumerate(map_names):\n",
    "    clear_output(wait=True)\n",
    "    bar.update(i)\n",
    "    time0 = time.time()\n",
    "    params_path[\"name_prior\"] = iname\n",
    "    X = cs.getmaps(params_maps, params_path)\n",
    "    X = cs.adaptation_maps(X, params_maps, params_path)\n",
    "    params_maps[\"iseed\"]=\"L\"+str(nseed_1[i])\n",
    "    cs.saveouts(mrec=X, A=A[L0], params_path=params_path, params_maps=params_maps, params_WT=params_WT, params_CS=params_CS, subdirs=subdirs)    \n",
    "\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
